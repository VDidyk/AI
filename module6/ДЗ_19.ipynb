{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VDidyk/AI/blob/master/module6/%D0%94%D0%97_19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Завдання 1\n",
        "Напишіть функцію, яка повертає список фраз з тексту, які відповідають певному шоблону. При необхідності можете добавити власні параметри.\n",
        "\n",
        "Протестуйте функцію на якомусь тексті."
      ],
      "metadata": {
        "id": "D56Rwjf4EXC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.chunk import RegexpParser\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "def get_phrases(text, regex, tag_name):\n",
        "    \"\"\"\n",
        "    Return list of phrases from text that matches regex.\n",
        "\n",
        "    Params:\n",
        "        text: str - original text\n",
        "        regex: str - regular expression\n",
        "        tag_name: str - tag name that is used in nltk tree\n",
        "\n",
        "    Return:\n",
        "        phrases: list[str] - list of phrases\n",
        "    \"\"\"\n",
        "\n",
        "    sentences = sent_tokenize(text)\n",
        "    phrases = []\n",
        "\n",
        "    grammar = f\"{tag_name}: {{ {regex} }}\"\n",
        "\n",
        "    cp = RegexpParser(grammar)\n",
        "\n",
        "    for sentence in sentences:\n",
        "        tokens = word_tokenize(sentence)\n",
        "        tagged_tokens = pos_tag(tokens)\n",
        "\n",
        "        tree = cp.parse(tagged_tokens)\n",
        "\n",
        "        for subtree in tree.subtrees():\n",
        "            if subtree.label() == tag_name:\n",
        "                phrase = \" \".join(word for word, tag in subtree.leaves())\n",
        "                phrases.append(phrase)\n",
        "\n",
        "    return phrases\n",
        "\n",
        "text = \"\"\"\n",
        "But I must explain to you how all this mistaken idea of denouncing pleasure and praising pain was born and I will give you a complete account of the system, and expound the actual teachings of the great explorer of the truth, the master-builder of human happiness. No one rejects, dislikes, or avoids pleasure itself, because it is pleasure, but because those who do not know how to pursue pleasure rationally encounter consequences that are extremely painful. Nor again is there anyone who loves or pursues or desires to obtain pain of itself, because it is pain, but because occasionally circumstances occur in which toil and pain can procure him some great pleasure. To take a trivial example, which of us ever undertakes laborious physical exercise, except to obtain some advantage from it? But who has any right to find fault with a man who chooses to enjoy a pleasure that has no annoying consequences, or one who avoids a pain that produces no resultant pleasure?\n",
        "\"\"\"\n",
        "\n",
        "regex = '<JJ> <NN>'\n",
        "tag_name = 'AN'\n",
        "phrases = get_phrases(text, regex, tag_name)\n",
        "\n",
        "print(\"Phrases matching the pattern:\", phrases)\n"
      ],
      "metadata": {
        "id": "G4Stff_zFQjv",
        "outputId": "3cd77f6f-945b-4419-90c9-753b729e9bf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Phrases matching the pattern: ['mistaken idea', 'complete account', 'great explorer', 'human happiness', 'great pleasure', 'trivial example', 'physical exercise', 'resultant pleasure']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    }
  ]
}