{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VDidyk/AI/blob/master/module6/%D0%9F%D1%80%D0%B0%D0%BA%D1%82%D0%B8%D0%BA%D0%B0_NLTK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Завдання 1\n",
        "Проведіть токенизацію тексту:\n",
        " * Розділіть текст на речення\n",
        " * Кожне речення розділіть на слова. Результатом має бути `list[list]` де скажімо `data[5][10]` означає 10-те слово з 5-го речення(індексація з 0)\n",
        " * Видаліть пунктуацію та стоп-слова\n",
        " * Створіть список усіх слів з тексту 'words`"
      ],
      "metadata": {
        "id": "nKUjkCZVCs08"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uq_Bleym56q9"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"Mrs Pig was very tired: 'Oh dear,' she said to her three little pigs, 'I can’t do this work anymore, I’m afraid you must leave home and make your own way in the world.' So the three little pigs set off.\n",
        "\n",
        "The first little pig met a man carrying a bundle of straw.\n",
        "\n",
        "'Excuse me,' said the first little pig politely. 'Would you please sell some of your straw so I can make a house?'\n",
        "\n",
        "The man readily agreed and the first little pig went off to find a good place to build his house.\n",
        "\n",
        "The other little pigs carried on along the road and, soon, they met a man carrying a bundle of sticks.\n",
        "\n",
        "'Excuse me,' said the little pig politely. 'Would you please sell me some sticks so I can build a house?'\n",
        "\n",
        "The man readily agreed and the little pig said goodbye to his brother.\n",
        "\n",
        "The third little pig didn’t think much of their ideas:\n",
        "\n",
        "'I’m going to build myself a much bigger, better, stronger house,' he thought, and he carried off down the road until he met a man with a cart load of bricks.\n",
        "\n",
        "'Excuse me,' said the third little pig, as politely as his mother had taught him. 'Please can you sell me some bricks so I can build a house?'\n",
        "\n",
        "'Of course,' said the man. 'Where would you like me to unload them?'\n",
        "\n",
        "The third little pig looked around and saw a nice patch of ground under a tree.\n",
        "\n",
        "'Over there,' he pointed.\n",
        "\n",
        "They all set to work and by nighttime the house of straw and the house of sticks were built but the house of bricks was only just beginning to rise above the ground. The first and second little pigs laughed, they thought their brother was really silly having to work so hard when they had finished.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7utYrH6mxuLJ",
        "outputId": "59535b3c-3723-44af-fe74-f909aab5da05"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = sent_tokenize(text)\n",
        "\n",
        "data = []\n",
        "\n",
        "all_words = []\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "for sentence in sentences:\n",
        "    words = word_tokenize(sentence)\n",
        "    words = [word.lower() for word in words if word.isalpha() and word.lower() not in stop_words]\n",
        "    data.append(words)\n",
        "    all_words.extend(words)\n",
        "\n",
        "data, all_words[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6q5vK0jLx9Ma",
        "outputId": "84035813-8eac-44a7-ed81-3bae2d6b94d6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([['mrs',\n",
              "   'pig',\n",
              "   'tired',\n",
              "   'dear',\n",
              "   'said',\n",
              "   'three',\n",
              "   'little',\n",
              "   'pigs',\n",
              "   'work',\n",
              "   'anymore',\n",
              "   'afraid',\n",
              "   'must',\n",
              "   'leave',\n",
              "   'home',\n",
              "   'make',\n",
              "   'way',\n",
              "   'world'],\n",
              "  ['three', 'little', 'pigs', 'set'],\n",
              "  ['first', 'little', 'pig', 'met', 'man', 'carrying', 'bundle', 'straw'],\n",
              "  ['said', 'first', 'little', 'pig', 'politely'],\n",
              "  ['please', 'sell', 'straw', 'make', 'house'],\n",
              "  ['man',\n",
              "   'readily',\n",
              "   'agreed',\n",
              "   'first',\n",
              "   'little',\n",
              "   'pig',\n",
              "   'went',\n",
              "   'find',\n",
              "   'good',\n",
              "   'place',\n",
              "   'build',\n",
              "   'house'],\n",
              "  ['little',\n",
              "   'pigs',\n",
              "   'carried',\n",
              "   'along',\n",
              "   'road',\n",
              "   'soon',\n",
              "   'met',\n",
              "   'man',\n",
              "   'carrying',\n",
              "   'bundle',\n",
              "   'sticks'],\n",
              "  ['said', 'little', 'pig', 'politely'],\n",
              "  ['please', 'sell', 'sticks', 'build', 'house'],\n",
              "  ['man', 'readily', 'agreed', 'little', 'pig', 'said', 'goodbye', 'brother'],\n",
              "  ['third',\n",
              "   'little',\n",
              "   'pig',\n",
              "   'think',\n",
              "   'much',\n",
              "   'ideas',\n",
              "   'going',\n",
              "   'build',\n",
              "   'much',\n",
              "   'bigger',\n",
              "   'better',\n",
              "   'stronger',\n",
              "   'house',\n",
              "   'thought',\n",
              "   'carried',\n",
              "   'road',\n",
              "   'met',\n",
              "   'man',\n",
              "   'cart',\n",
              "   'load',\n",
              "   'bricks'],\n",
              "  ['said', 'third', 'little', 'pig', 'politely', 'mother', 'taught'],\n",
              "  ['sell', 'bricks', 'build', 'house'],\n",
              "  ['course', 'said', 'man'],\n",
              "  ['would', 'like', 'unload'],\n",
              "  ['third',\n",
              "   'little',\n",
              "   'pig',\n",
              "   'looked',\n",
              "   'around',\n",
              "   'saw',\n",
              "   'nice',\n",
              "   'patch',\n",
              "   'ground',\n",
              "   'tree'],\n",
              "  ['pointed'],\n",
              "  ['set',\n",
              "   'work',\n",
              "   'nighttime',\n",
              "   'house',\n",
              "   'straw',\n",
              "   'house',\n",
              "   'sticks',\n",
              "   'built',\n",
              "   'house',\n",
              "   'bricks',\n",
              "   'beginning',\n",
              "   'rise',\n",
              "   'ground'],\n",
              "  ['first',\n",
              "   'second',\n",
              "   'little',\n",
              "   'pigs',\n",
              "   'laughed',\n",
              "   'thought',\n",
              "   'brother',\n",
              "   'really',\n",
              "   'silly',\n",
              "   'work',\n",
              "   'hard',\n",
              "   'finished']],\n",
              " ['mrs',\n",
              "  'pig',\n",
              "  'tired',\n",
              "  'dear',\n",
              "  'said',\n",
              "  'three',\n",
              "  'little',\n",
              "  'pigs',\n",
              "  'work',\n",
              "  'anymore'])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Завдання 2\n",
        "\n",
        " * Зробіть стемінг слів\n",
        " * Зробіть лематизацію слів\n",
        " * Створіть `pandas.DataFrame` зі словами, що мають різний результат при стемінгу та лематизації. Має бути 3 стовпчика:\n",
        "  * оригінальне сово\n",
        "  * результат стемінгу\n",
        "  * результат лематизації\n"
      ],
      "metadata": {
        "id": "JmES6y8NDwgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "import pandas as pd\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def get_wordnet_pos(word):\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\n",
        "                \"N\": wordnet.NOUN,\n",
        "                \"V\": wordnet.VERB,\n",
        "                \"R\": wordnet.ADV}\n",
        "\n",
        "    return tag_dict.get(tag, wordnet.NOUN)\n",
        "\n",
        "\n",
        "results = []\n",
        "for word in words:\n",
        "    stem = stemmer.stem(word)\n",
        "    lemma = lemmatizer.lemmatize(word, get_wordnet_pos(word))\n",
        "    if stem != lemma:\n",
        "        results.append((word, stem, lemma))\n",
        "\n",
        "df = pd.DataFrame(results, columns=['Original Word', 'Stem', 'Lemma'])\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "id": "DNtDBH8lEWWl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2421d80d-3109-41a7-eee0-8ec2a00038a0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Original Word    Stem   Lemma\n",
            "0        little   littl  little\n",
            "1        really  realli  really\n",
            "2         silly   silli   silly\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Завдання 3\n",
        "Виділіть фрази за такими шаблонами:\n",
        "  * прикметник + іменник\n",
        "  * (хоча б 1 прикметник) + іменник\n",
        "  * (прислівник + дієслово) АБО (дієслово + прислівник)"
      ],
      "metadata": {
        "id": "D56Rwjf4EXC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import wordnet\n",
        "import re\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "def extract_phrases(text, pattern):\n",
        "    sentences = sent_tokenize(text)\n",
        "    phrases = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "        tokens = word_tokenize(sentence)\n",
        "        tagged = pos_tag(tokens)\n",
        "\n",
        "        chunker = nltk.RegexpParser(pattern)\n",
        "        parsed = chunker.parse(tagged)\n",
        "\n",
        "        for subtree in parsed.subtrees():\n",
        "            if subtree.label() == 'PHRASE':\n",
        "                temp = [w for w, t in subtree.leaves()]\n",
        "                phrases.append(' '.join(temp))\n",
        "\n",
        "    return phrases\n",
        "\n",
        "patterns = [\n",
        "    \"PHRASE: {<JJ>+<NN>}\",\n",
        "    \"PHRASE: {<RB>+<VB>|<VB>+<RB>}\"\n",
        "]\n",
        "\n",
        "for pattern in patterns:\n",
        "    extracted_phrases = extract_phrases(text,pattern)\n",
        "    print(f\"{extracted_phrases}\\n\")\n"
      ],
      "metadata": {
        "id": "G4Stff_zFQjv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70157da5-a943-4b75-c0f8-6149b5570817"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['own way', 'first little pig', 'first little pig', 'first little pig', 'good place', 'little pig', 'little pig', 'third little pig', 'cart load', 'third little pig', \"'Of course\", 'third little pig', 'nice patch']\n",
            "\n",
            "['’ t', 'work so']\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    }
  ]
}