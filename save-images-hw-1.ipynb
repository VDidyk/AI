{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3866368,"sourceType":"datasetVersion","datasetId":849073}],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import ConcatDataset\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom PIL import Image\ndata_dir='/kaggle/input/fruit-recognition/train/train'\nclass ImageDataset(torch.utils.data.Dataset):\n    \"\"\"\n    Custom Dataset for loading and preprocessing images.\n    \"\"\"\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.classes = os.listdir(root_dir)\n        self.image_paths = self.get_pathes(root_dir)\n        self.class_to_idx = {label: i for i, label in enumerate(self.classes)}\n\n        self.transform = transform\n\n    def get_pathes(self, root):\n        image_paths = []\n        labels = os.listdir(root)\n\n        for label in labels:\n            images = os.listdir(os.path.join(root, label))    \n            image_paths.extend([os.path.join(root, label, image) for image in images])\n        return image_paths\n\n    def __len__(self):\n        \"\"\"\n        Returns the number of images in the dataset.\n        \"\"\"\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        \"\"\"\n        Loads and preprocesses an image at a given index.\n\n        Args:\n          idx (int): Index of the image to return.\n\n        Returns:\n          tuple: A tuple containing the preprocessed image and its label (if available).\n        \"\"\"\n        image_path = self.image_paths[idx]\n        image = Image.open(image_path).convert('RGB')  # Assuming RGB images\n        if self.transform:\n            image = self.transform(image)\n\n        # Add logic to load labels if available (modify based on your data structure)\n        label_name = os.path.normpath(image_path).split(os.path.sep)[-2]\n\n        return image, self.class_to_idx[label_name]\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T06:55:11.164939Z","iopub.execute_input":"2024-04-17T06:55:11.165384Z","iopub.status.idle":"2024-04-17T06:55:11.177831Z","shell.execute_reply.started":"2024-04-17T06:55:11.165357Z","shell.execute_reply":"2024-04-17T06:55:11.176850Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"custom_train_data = ImageDataset(data_dir)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T06:55:11.179092Z","iopub.execute_input":"2024-04-17T06:55:11.179470Z","iopub.status.idle":"2024-04-17T06:55:14.332264Z","shell.execute_reply.started":"2024-04-17T06:55:11.179435Z","shell.execute_reply":"2024-04-17T06:55:14.331332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_classes=custom_train_data.classes","metadata":{"execution":{"iopub.status.busy":"2024-04-17T06:55:14.334957Z","iopub.execute_input":"2024-04-17T06:55:14.335407Z","iopub.status.idle":"2024-04-17T06:55:14.340678Z","shell.execute_reply.started":"2024-04-17T06:55:14.335362Z","shell.execute_reply":"2024-04-17T06:55:14.339556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import random_split\n\ntotal_size = len(custom_train_data)\ntrain_size = int(0.8 * total_size)\ntest_size = total_size - train_size\n\ntrain_dataset, test_dataset = random_split(custom_train_data, [train_size, test_size])","metadata":{"execution":{"iopub.status.busy":"2024-04-17T06:55:14.342171Z","iopub.execute_input":"2024-04-17T06:55:14.342539Z","iopub.status.idle":"2024-04-17T06:55:14.367680Z","shell.execute_reply.started":"2024-04-17T06:55:14.342511Z","shell.execute_reply":"2024-04-17T06:55:14.366776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(train_dataset))\nprint(len(test_dataset))","metadata":{"execution":{"iopub.status.busy":"2024-04-17T06:55:14.368788Z","iopub.execute_input":"2024-04-17T06:55:14.369062Z","iopub.status.idle":"2024-04-17T06:55:14.374273Z","shell.execute_reply.started":"2024-04-17T06:55:14.369037Z","shell.execute_reply":"2024-04-17T06:55:14.373349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_transform = transforms.Compose([\n#     transforms.Resize((100, 100)), # Зміна розміру зображення до 256x256 пікселів\n#     transforms.RandomHorizontalFlip(p=5), # Випадково перевернути по горизонталі з ймовірністю 50%\n#     transforms.ToTensor(), # Перетворити зображення у тензори PyTorch\n# ])\n\n# test_transform = transforms.Compose([\n#     transforms.Resize((100, 100)), # Зміна розміру зображення до 256x256 пікселів\n#     transforms.ToTensor(), # Перетворити зображення у тензори PyTorch\n# ])\n\n# train_dataset.transform = train_transform\n# test_dataset.transform = test_transform","metadata":{"execution":{"iopub.status.busy":"2024-04-17T06:55:14.375721Z","iopub.execute_input":"2024-04-17T06:55:14.376399Z","iopub.status.idle":"2024-04-17T06:55:14.382879Z","shell.execute_reply.started":"2024-04-17T06:55:14.376369Z","shell.execute_reply":"2024-04-17T06:55:14.381976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_transform = transforms.Compose([\n    transforms.Resize((299, 299)), # Зміна розміру зображення до 256x256 пікселів\n    transforms.ToTensor(), # Перетворити зображення у тензори PyTorch\n])\n\n\nclass TransformDataset(torch.utils.data.Dataset):\n    def __init__(self, subset, transform=None):\n        self.subset = subset\n        self.transform = transform\n\n    def __getitem__(self, index):\n        x, y = self.subset[index]\n        if self.transform:\n            x = self.transform(x)\n        return x, y\n\n    def __len__(self):\n        return len(self.subset)\n\n\ntrain_data = TransformDataset(train_dataset, transform = test_transform)\ntest_data = TransformDataset(test_dataset, transform = test_transform)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T06:55:14.384261Z","iopub.execute_input":"2024-04-17T06:55:14.384580Z","iopub.status.idle":"2024-04-17T06:55:14.393410Z","shell.execute_reply.started":"2024-04-17T06:55:14.384558Z","shell.execute_reply":"2024-04-17T06:55:14.392342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch import nn\nimport torch.nn.functional as F\nimport numpy as np\nfrom torchvision import models\nimport torch\n\nclass TransferLearningClassifier(nn.Module):\n    def __init__(self, num_classes=10):\n        super().__init__()\n\n        # Використання Inception v3\n        inception = models.inception_v3(pretrained=True, aux_logits=False)\n        \n        # Від'єднання градієнтів для всіх параметрів моделі\n        for param in inception.parameters():\n            param.requires_grad = False\n        \n        # Кількість нейронів на виході основного класифікатора (не враховуючи допоміжний вихід)\n        in_features = inception.fc.in_features\n        \n        # Заміна останнього класифікаційного шару на Identity, щоб використати наш шар\n        inception.fc = nn.Identity()\n        \n        # Ініціалізація модулів\n        self.feature_extractor = inception\n        \n        self.dropout = nn.Dropout(0.2)\n        self.linear = nn.Linear(in_features, num_classes)\n        \n\n    def forward(self, x):\n        # Отримання ознак з feature extractor\n        out = self.feature_extractor(x)  # out має розмір (batch_size, in_features)\n        \n        out = self.dropout(out)\n        out = self.linear(out)\n        \n        return out\n\n\n    def predict(self, X, device='cpu'):\n        # Перетворення вхідних даних у тензор та перенесення на вказаний пристрій\n        X = torch.FloatTensor(np.array(X)).to(device)\n\n        with torch.no_grad():\n            y_pred = F.softmax(self.forward(X), dim=-1)\n\n        return y_pred.cpu().numpy()\n\n\n# Ініціалізація моделі\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = TransferLearningClassifier(num_classes=len(['hem', 'all'])).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T06:55:14.394533Z","iopub.execute_input":"2024-04-17T06:55:14.394846Z","iopub.status.idle":"2024-04-17T06:55:14.614713Z","shell.execute_reply.started":"2024-04-17T06:55:14.394821Z","shell.execute_reply":"2024-04-17T06:55:14.613704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q torchsummary","metadata":{"execution":{"iopub.status.busy":"2024-04-17T06:55:14.618503Z","iopub.execute_input":"2024-04-17T06:55:14.618910Z","iopub.status.idle":"2024-04-17T06:55:27.982892Z","shell.execute_reply.started":"2024-04-17T06:55:14.618885Z","shell.execute_reply":"2024-04-17T06:55:27.981539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchsummary import summary\n\nsummary(model, input_size=(3, 256, 256))","metadata":{"execution":{"iopub.status.busy":"2024-04-17T06:55:27.984414Z","iopub.execute_input":"2024-04-17T06:55:27.984715Z","iopub.status.idle":"2024-04-17T06:55:28.587892Z","shell.execute_reply.started":"2024-04-17T06:55:27.984688Z","shell.execute_reply":"2024-04-17T06:55:28.586867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Визначення функції втрат та оптимізатора\n\nloss_fn = nn.CrossEntropyLoss()\n\n# Оптимізатор (SGD) для оновлення ваг моделі\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T06:55:28.589427Z","iopub.execute_input":"2024-04-17T06:55:28.589898Z","iopub.status.idle":"2024-04-17T06:55:28.597101Z","shell.execute_reply.started":"2024-04-17T06:55:28.589862Z","shell.execute_reply":"2024-04-17T06:55:28.596112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# @title Функція для тренування\nimport time\n\ndef train(model, optimizer, loss_fn, train_dl, val_dl,\n          metrics=None, metrics_name=None, epochs=20, device='cpu', task='regression'):\n    '''\n    Runs training loop for classification problems. Returns Keras-style\n    per-epoch history of loss and accuracy over training and validation data.\n\n    Parameters\n    ----------\n    model : nn.Module\n        Neural network model\n    optimizer : torch.optim.Optimizer\n        Search space optimizer (e.g. Adam)\n    loss_fn :\n        Loss function (e.g. nn.CrossEntropyLoss())\n    train_dl :\n        Iterable dataloader for training data.\n    val_dl :\n        Iterable dataloader for validation data.\n    metrics: list\n        List of sklearn metrics functions to be calculated\n    metrics_name: list\n        List of matrics names\n    epochs : int\n        Number of epochs to run\n    device : string\n        Specifies 'cuda' or 'cpu'\n    task : string\n        type of problem. It can be regression, binary or multiclass\n\n    Returns\n    -------\n    Dictionary\n        Similar to Keras' fit(), the output dictionary contains per-epoch\n        history of training loss, training accuracy, validation loss, and\n        validation accuracy.\n    '''\n\n    print('train() called: model=%s, opt=%s(lr=%f), epochs=%d, device=%s\\n' % \\\n          (type(model).__name__, type(optimizer).__name__,\n           optimizer.param_groups[0]['lr'], epochs, device))\n\n    metrics = metrics if metrics else []\n    metrics_name = metrics_name if metrics_name else [metric.__name__ for metric in metrics]\n\n    history = {} # Collects per-epoch loss and metrics like Keras' fit().\n    history['loss'] = []\n    history['val_loss'] = []\n    for name in metrics_name:\n        history[name] = []\n        history[f'val_{name}'] = []\n\n    start_time_train = time.time()\n\n    for epoch in range(epochs):\n\n        # --- TRAIN AND EVALUATE ON TRAINING SET -----------------------------\n        start_time_epoch = time.time()\n\n        model.train()\n        history_train = {name: 0 for name in ['loss']+metrics_name}\n\n        for batch in train_dl:\n            x    = batch[0].to(device)\n            y    = batch[1].to(device)\n            y_pred = model(x)\n            loss = loss_fn(y_pred, y)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            y_pred = y_pred.detach().cpu().numpy()\n            y = y.detach().cpu().numpy()\n\n\n            history_train['loss'] += loss.item() * x.size(0)\n            for name, func in zip(metrics_name, metrics):\n                try:\n                    history_train[name] += func(y, y_pred) * x.size(0)\n                except:\n                    if task == 'binary': y_pred_ = y_pred.round()\n                    elif task == 'multiclass': y_pred_ = y_pred.argmax(axis=-1)\n                    history_train[name] += func(y, y_pred_) * x.size(0)\n\n        for name in history_train:\n            history_train[name] /= len(train_dl.dataset)\n\n\n        # --- EVALUATE ON VALIDATION SET -------------------------------------\n        model.eval()\n        history_val = {'val_' + name: 0 for name in metrics_name+['loss']}\n\n        with torch.no_grad():\n            for batch in val_dl:\n                x    = batch[0].to(device)\n                y    = batch[1].to(device)\n                y_pred = model(x)\n                loss = loss_fn(y_pred, y)\n\n                y_pred = y_pred.cpu().numpy()\n                y = y.cpu().numpy()\n\n                history_val['val_loss'] += loss.item() * x.size(0)\n                for name, func in zip(metrics_name, metrics):\n                    try:\n                        history_val['val_'+name] += func(y, y_pred) * x.size(0)\n                    except:\n                        if task == 'binary': y_pred_ = y_pred.round()\n                        elif task == 'multiclass': y_pred_ = y_pred.argmax(axis=-1)\n\n                        history_val['val_'+name] += func(y, y_pred_) * x.size(0)\n\n        for name in history_val:\n            history_val[name] /= len(val_dl.dataset)\n\n        # PRINTING RESULTS\n\n        end_time_epoch = time.time()\n\n        for name in history_train:\n            history[name].append(history_train[name])\n            history['val_'+name].append(history_val['val_'+name])\n\n        total_time_epoch = end_time_epoch - start_time_epoch\n\n        print(f'Epoch {epoch+1:4d} {total_time_epoch:4.0f}sec', end='\\t')\n        for name in history_train:\n            print(f'{name}: {history[name][-1]:10.3g}', end='\\t')\n            print(f\"val_{name}: {history['val_'+name][-1]:10.3g}\", end='\\t')\n        print()\n\n    # END OF TRAINING LOOP\n\n    end_time_train       = time.time()\n    total_time_train     = end_time_train - start_time_train\n    print()\n    print('Time total:     %5.2f sec' % (total_time_train))\n\n    return history\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T06:55:28.598584Z","iopub.execute_input":"2024-04-17T06:55:28.598859Z","iopub.status.idle":"2024-04-17T06:55:28.621279Z","shell.execute_reply.started":"2024-04-17T06:55:28.598834Z","shell.execute_reply":"2024-04-17T06:55:28.620341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 64\ntrain_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size)\ntest_loader = torch.utils.data.DataLoader(test_data, shuffle=True, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T06:55:28.622454Z","iopub.execute_input":"2024-04-17T06:55:28.622792Z","iopub.status.idle":"2024-04-17T06:55:28.632071Z","shell.execute_reply.started":"2024-04-17T06:55:28.622769Z","shell.execute_reply":"2024-04-17T06:55:28.631125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, roc_auc_score\n\nhistory = train(model, optimizer, loss_fn, train_loader, test_loader,\n                epochs=20,\n                metrics=[accuracy_score],\n                device=device,\n                task='multiclass')","metadata":{"execution":{"iopub.status.busy":"2024-04-17T06:55:28.633211Z","iopub.execute_input":"2024-04-17T06:55:28.633510Z","iopub.status.idle":"2024-04-17T07:19:27.942756Z","shell.execute_reply.started":"2024-04-17T06:55:28.633487Z","shell.execute_reply":"2024-04-17T07:19:27.941703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_metric(history, name):\n    plt.title(f\"Model results with {name}\")\n    plt.plot(history[name], label='train')\n    plt.plot(history['val_'+name], label='val')\n    plt.xlabel('Epoch')\n    plt.ylabel(name)\n    plt.legend()\n\n\nplot_metric(history, 'loss')","metadata":{"execution":{"iopub.status.busy":"2024-04-17T07:19:27.944332Z","iopub.execute_input":"2024-04-17T07:19:27.944659Z","iopub.status.idle":"2024-04-17T07:19:28.314856Z","shell.execute_reply.started":"2024-04-17T07:19:27.944631Z","shell.execute_reply":"2024-04-17T07:19:28.313801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_metric(history, 'accuracy_score')","metadata":{"execution":{"iopub.status.busy":"2024-04-17T07:19:28.316065Z","iopub.execute_input":"2024-04-17T07:19:28.316411Z","iopub.status.idle":"2024-04-17T07:19:28.705312Z","shell.execute_reply.started":"2024-04-17T07:19:28.316384Z","shell.execute_reply":"2024-04-17T07:19:28.704341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import ConfusionMatrixDisplay\n\nmodel = model.to('cpu')\nmodel.eval()\n\nbatch_size = 1024 \nloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n\ny_true = []\ny_pred = []\n\nfor X_batch, y_batch in loader:\n    batch_pred = model.predict(X_batch)\n    \n    y_true.extend(y_batch.tolist())\n    y_pred.extend(batch_pred.argmax(-1).tolist())\n\ndisplay_labels = all_classes\n\nConfusionMatrixDisplay.from_predictions(y_true, y_pred, display_labels=display_labels)\nplt.xticks(rotation=90)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-17T07:27:59.013141Z","iopub.execute_input":"2024-04-17T07:27:59.013881Z","iopub.status.idle":"2024-04-17T07:29:33.731785Z","shell.execute_reply.started":"2024-04-17T07:27:59.013850Z","shell.execute_reply":"2024-04-17T07:29:33.730869Z"},"trusted":true},"execution_count":null,"outputs":[]}]}